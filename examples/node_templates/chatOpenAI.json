{
  "_metadata": {
    "node_type": "chatOpenAI",
    "name": "chatOpenAI",
    "label": "ChatOpenAI",
    "category": "Chat Models",
    "version": 8.3,
    "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
    "base_classes": [
      "ChatOpenAI",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "extracted_date": "2025-10-17",
    "source": "Flowise instance",
    "usage_note": "Replace ID and customize inputs before use"
  },
  "node": {
    "id": "chatOpenAI_0",
    "position": {
      "x": 864.2151198288125,
      "y": -454.979480545245
    },
    "type": "customNode",
    "data": {
      "loadMethods": {},
      "label": "ChatOpenAI",
      "name": "chatOpenAI",
      "version": 8.3,
      "type": "ChatOpenAI",
      "icon": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/openai.svg",
      "category": "Chat Models",
      "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
      "baseClasses": [
        "ChatOpenAI",
        "BaseChatOpenAI",
        "BaseChatModel",
        "BaseLanguageModel",
        "Runnable"
      ],
      "credential": "cce50fc6-ef42-43e8-9bb2-0638c0bf23be",
      "inputs": {
        "cache": "{{inMemoryCache_0.data.instance}}",
        "modelName": "gpt-4o-mini",
        "temperature": 0.9,
        "streaming": true,
        "maxTokens": "",
        "topP": "",
        "frequencyPenalty": "",
        "presencePenalty": "",
        "timeout": "",
        "strictToolCalling": "",
        "stopSequence": "",
        "basepath": "",
        "proxyUrl": "",
        "baseOptions": "",
        "allowImageUploads": "",
        "imageResolution": "low",
        "reasoning": "",
        "reasoningEffort": "",
        "reasoningSummary": ""
      },
      "filePath": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/ChatOpenAI.js",
      "inputAnchors": [
        {
          "label": "Cache",
          "name": "cache",
          "type": "BaseCache",
          "optional": true,
          "id": "chatOpenAI_0-input-cache-BaseCache",
          "display": true
        }
      ],
      "inputParams": [
        {
          "label": "Connect Credential",
          "name": "credential",
          "type": "credential",
          "credentialNames": [
            "openAIApi"
          ],
          "id": "chatOpenAI_0-input-credential-credential",
          "display": true
        },
        {
          "label": "Model Name",
          "name": "modelName",
          "type": "asyncOptions",
          "loadMethod": "listModels",
          "default": "gpt-4o-mini",
          "id": "chatOpenAI_0-input-modelName-asyncOptions",
          "display": true
        },
        {
          "label": "Temperature",
          "name": "temperature",
          "type": "number",
          "step": 0.1,
          "default": 0.9,
          "optional": true,
          "id": "chatOpenAI_0-input-temperature-number",
          "display": true
        },
        {
          "label": "Streaming",
          "name": "streaming",
          "type": "boolean",
          "default": true,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-streaming-boolean",
          "display": true
        },
        {
          "label": "Max Tokens",
          "name": "maxTokens",
          "type": "number",
          "step": 1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-maxTokens-number",
          "display": true
        },
        {
          "label": "Top Probability",
          "name": "topP",
          "type": "number",
          "step": 0.1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-topP-number",
          "display": true
        },
        {
          "label": "Frequency Penalty",
          "name": "frequencyPenalty",
          "type": "number",
          "step": 0.1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-frequencyPenalty-number",
          "display": true
        },
        {
          "label": "Presence Penalty",
          "name": "presencePenalty",
          "type": "number",
          "step": 0.1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-presencePenalty-number",
          "display": true
        },
        {
          "label": "Timeout",
          "name": "timeout",
          "type": "number",
          "step": 1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-timeout-number",
          "display": true
        },
        {
          "label": "Strict Tool Calling",
          "name": "strictToolCalling",
          "type": "boolean",
          "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-strictToolCalling-boolean",
          "display": true
        },
        {
          "label": "Stop Sequence",
          "name": "stopSequence",
          "type": "string",
          "rows": 4,
          "optional": true,
          "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
          "additionalParams": true,
          "id": "chatOpenAI_0-input-stopSequence-string",
          "display": true
        },
        {
          "label": "BasePath",
          "name": "basepath",
          "type": "string",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-basepath-string",
          "display": true
        },
        {
          "label": "Proxy Url",
          "name": "proxyUrl",
          "type": "string",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-proxyUrl-string",
          "display": true
        },
        {
          "label": "BaseOptions",
          "name": "baseOptions",
          "type": "json",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-baseOptions-json",
          "display": true
        },
        {
          "label": "Allow Image Uploads",
          "name": "allowImageUploads",
          "type": "boolean",
          "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
          "default": false,
          "optional": true,
          "id": "chatOpenAI_0-input-allowImageUploads-boolean",
          "display": true
        },
        {
          "label": "Image Resolution",
          "description": "This parameter controls the resolution in which the model views the image.",
          "name": "imageResolution",
          "type": "options",
          "options": [
            {
              "label": "Low",
              "name": "low"
            },
            {
              "label": "High",
              "name": "high"
            },
            {
              "label": "Auto",
              "name": "auto"
            }
          ],
          "default": "low",
          "optional": false,
          "show": {
            "allowImageUploads": true
          },
          "id": "chatOpenAI_0-input-imageResolution-options",
          "display": false
        },
        {
          "label": "Reasoning",
          "description": "Whether the model supports reasoning. Only applicable for reasoning models.",
          "name": "reasoning",
          "type": "boolean",
          "default": false,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-reasoning-boolean",
          "display": true
        },
        {
          "label": "Reasoning Effort",
          "description": "Constrains effort on reasoning for reasoning models",
          "name": "reasoningEffort",
          "type": "options",
          "options": [
            {
              "label": "Low",
              "name": "low"
            },
            {
              "label": "Medium",
              "name": "medium"
            },
            {
              "label": "High",
              "name": "high"
            }
          ],
          "additionalParams": true,
          "show": {
            "reasoning": true
          },
          "id": "chatOpenAI_0-input-reasoningEffort-options",
          "display": false
        },
        {
          "label": "Reasoning Summary",
          "description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process",
          "name": "reasoningSummary",
          "type": "options",
          "options": [
            {
              "label": "Auto",
              "name": "auto"
            },
            {
              "label": "Concise",
              "name": "concise"
            },
            {
              "label": "Detailed",
              "name": "detailed"
            }
          ],
          "additionalParams": true,
          "show": {
            "reasoning": true
          },
          "id": "chatOpenAI_0-input-reasoningSummary-options",
          "display": false
        }
      ],
      "outputs": {},
      "outputAnchors": [
        {
          "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
          "name": "chatOpenAI",
          "label": "ChatOpenAI",
          "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
          "type": "ChatOpenAI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
        }
      ],
      "id": "chatOpenAI_0",
      "selected": false
    },
    "width": 300,
    "height": 676,
    "positionAbsolute": {
      "x": 864.2151198288125,
      "y": -454.979480545245
    },
    "selected": false,
    "dragging": false
  }
}
{
  "nodes": [
    {
      "id": "chatOpenAI_2",
      "position": {
        "x": 100,
        "y": 100
      },
      "type": "customNode",
      "data": {
        "loadMethods": {},
        "label": "ChatOpenAI",
        "name": "chatOpenAI",
        "version": 8.3,
        "type": "ChatOpenAI",
        "icon": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/openai.svg",
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "credential": "cce50fc6-ef42-43e8-9bb2-0638c0bf23be",
        "inputs": {
          "cache": "{{inMemoryCache_0.data.instance}}",
          "modelName": "gpt-4o-mini",
          "temperature": 0.9,
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoning": "",
          "reasoningEffort": "",
          "reasoningSummary": ""
        },
        "filePath": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/chatmodels/ChatOpenAI/ChatOpenAI.js",
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_2-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_2-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_2-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_2-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_2-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_2-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_2-input-imageResolution-options",
            "display": false
          },
          {
            "label": "Reasoning",
            "description": "Whether the model supports reasoning. Only applicable for reasoning models.",
            "name": "reasoning",
            "type": "boolean",
            "default": false,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-reasoning-boolean",
            "display": true
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "additionalParams": true,
            "show": {
              "reasoning": true
            },
            "id": "chatOpenAI_2-input-reasoningEffort-options",
            "display": false
          },
          {
            "label": "Reasoning Summary",
            "description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process",
            "name": "reasoningSummary",
            "type": "options",
            "options": [
              {
                "label": "Auto",
                "name": "auto"
              },
              {
                "label": "Concise",
                "name": "concise"
              },
              {
                "label": "Detailed",
                "name": "detailed"
              }
            ],
            "additionalParams": true,
            "show": {
              "reasoning": true
            },
            "id": "chatOpenAI_2-input-reasoningSummary-options",
            "display": false
          }
        ],
        "outputs": {},
        "outputAnchors": [
          {
            "id": "chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "id": "chatOpenAI_2",
        "selected": false
      },
      "width": 300,
      "height": 676,
      "positionAbsolute": {
        "x": 100,
        "y": 100
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "documentStore_0",
      "position": {
        "x": 100,
        "y": 350
      },
      "type": "customNode",
      "data": {
        "loadMethods": {},
        "label": "Document Store",
        "name": "documentStore",
        "version": 1,
        "type": "Document",
        "icon": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/documentloaders/DocumentStore/dstore.svg",
        "category": "Document Loaders",
        "description": "Load data from pre-configured document stores",
        "baseClasses": [
          "Document"
        ],
        "inputs": {
          "selectedStore": "518dd34f-ad11-4642-a145-afaa42cd78bb",
          "storeId": "my-documents"
        },
        "outputs": {
          "output": "document"
        },
        "filePath": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/documentloaders/DocumentStore/DocStoreLoader.js",
        "inputAnchors": [],
        "inputParams": [
          {
            "label": "Select Store",
            "name": "selectedStore",
            "type": "asyncOptions",
            "loadMethod": "listStores",
            "id": "documentStore_0-input-selectedStore-asyncOptions"
          }
        ],
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "documentStore_2-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "documentStore_2-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "id": "documentStore_0",
        "selected": false
      },
      "width": 300,
      "height": 312,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 100,
        "y": 350
      }
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 500,
        "y": 100
      },
      "type": "customNode",
      "data": {
        "label": "Conversational Retrieval QA Chain",
        "name": "conversationalRetrievalQAChain",
        "version": 3,
        "type": "ConversationalRetrievalQAChain",
        "icon": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/chains/ConversationalRetrievalQAChain/qa.svg",
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "inputs": {
          "model": "{{chatOpenAI_0.data.instance}}",
          "vectorStoreRetriever": "{{memoryVectorStore_0.data.instance}}",
          "memory": "",
          "returnSourceDocuments": "",
          "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "You are a dedicated and resourceful assistant, designed to help users find information and generate leads by leveraging the data stored in your memory. Your primary focus is to provide accurate and relevant answers based on the provided context, ensuring users feel supported and informed. Your goal is to enhance user experience by delivering precise information and encouraging further engagement.\n\nUsing the provided context, answer the user's question to the best of your ability with the resources available. If the context does not contain information relevant to the user's inquiry, respond with a polite and engaging message to maintain user interest and encourage further interaction.\n\nGuidelines:\n\n    Utilize the given context to provide accurate and relevant answers.\n    If no relevant information is available within the context, respond with: \"Thank you for your question! While I don't have the information at the moment, I'm here to assist with any other queries you might have or help connect you to someone who can.\"\n    Avoid fabricating answers and focus on fostering a positive user experience.\n\nContext:\n{context}",
          "inputModeration": ""
        },
        "filePath": "/home/yermek/Flowise/packages/server/node_modules/flowise-components/dist/nodes/chains/ConversationalRetrievalQAChain/ConversationalRetrievalQAChain.js",
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
          }
        ],
        "outputs": {},
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "id": "conversationalRetrievalQAChain_0",
        "selected": false
      },
      "width": 300,
      "height": 532,
      "selected": false,
      "positionAbsolute": {
        "x": 500,
        "y": 100
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "id": "chatOpenAI_2-chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "source": "chatOpenAI_2",
      "target": "conversationalRetrievalQAChain_0",
      "sourceHandle": "chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "data": {
        "label": ""
      }
    },
    {
      "id": "documentStore_0-documentStore_0-output-0-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "source": "documentStore_0",
      "target": "conversationalRetrievalQAChain_0",
      "sourceHandle": "documentStore_0-output-0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "data": {
        "label": ""
      }
    }
  ],
  "viewport": {
    "x": 0,
    "y": 0,
    "zoom": 1
  }
}